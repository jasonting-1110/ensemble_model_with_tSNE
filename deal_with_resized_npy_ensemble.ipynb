{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOR8有問題! 剔除\n",
    "把NOR1~NOR7複製到另一資料夾\n",
    "copy時會有檔案名稱重複的問題，會被覆蓋->必須針對不同folder中的檔案重新命名!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "# from copy_file import copy_nor\n",
    "\n",
    "# # SD-OCT\n",
    "# src_base_path = r'\\\\BOIL-NAS\\homes\\311514061\\2024-5haveBG-SD-OCT dental calculus\\2024dentalCalculus'\n",
    "# dest_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\NOR'\n",
    "\n",
    "\n",
    "# copy_nor(src_base_path,dest_path)\n",
    "\n",
    "\n",
    "#OCTA\n",
    "src_base_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA'\n",
    "dest_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\NOR'\n",
    "\n",
    "# copy_nor(src_base_path,dest_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把supra1~supra5複製到另一資料夾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在复制 \\\\BOIL-NAS\\homes\\311514061\\2024-5haveBG-SD-OCT dental calculus\\2024dentalCalculus\\supra6\\npy_resize\\npy 中的文件到 D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\CAL\n",
      "正在复制 \\\\BOIL-NAS\\homes\\311514061\\2024-5haveBG-SD-OCT dental calculus\\2024dentalCalculus\\supra7\\npy_resize\\npy 中的文件到 D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\CAL\n",
      "正在复制 \\\\BOIL-NAS\\homes\\311514061\\2024-5haveBG-SD-OCT dental calculus\\2024dentalCalculus\\supra8\\npy_resize\\npy 中的文件到 D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\CAL\n",
      "完成复制任务\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "# from copy_file import copy_supra\n",
    "\n",
    "# # 定义源和目标路径\n",
    "# src_base_path = r'\\\\BOIL-NAS\\homes\\311514061\\2024-5haveBG-SD-OCT dental calculus\\2024dentalCalculus'\n",
    "# dest_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\CAL'\n",
    "# copy_supra(src_base_path,dest_path)\n",
    "\n",
    "#OCTA\n",
    "src_base_path = r'\\\\BOIL-NAS\\homes\\311514061\\2024_dc_OCTA'\n",
    "dest_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\CAL'\n",
    "copy_supra(src_base_path,dest_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目標: 盡量把每個步驟都寫成函式存成py並放在同目錄，有需要時呼叫，這樣版面較整潔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\reqiured_funcs\") #存取所需函式的路徑\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先把原始檔案npy轉png方便查看，把其中有問題的資料刪除，以避免不良訓練成果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可能是data失衡導致的overfit，不一定要用此查看raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvt_to_png\n",
    "\n",
    "src_cal_folder=r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\CAL'\n",
    "png_cal_folder=r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\CAL_png'\n",
    "cvt_to_png.convert_npy_to_png(src_cal_folder,png_cal_folder)\n",
    "\n",
    "\n",
    "#OCTA\n",
    "# src_nor_folder=r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\NOR'\n",
    "# png_nor_folder=r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\NOR_png'\n",
    "# cvt_to_png.convert_npy_to_png(src_nor_folder,png_nor_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "透過引入以上路徑中的del_files.py，將沒用的file/folder刪除(慎用)\n",
    "可以一次刪除多個目錄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from del_files import delete_files_in_directory,delete_folder\n",
    "\n",
    "# # directory_to_clean=[r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\train',\n",
    "# #                     r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\train_aug',\n",
    "# #                     r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\train_aug_jpeg',\n",
    "# #                     r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\test',\n",
    "# #                     r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\test_png',]\n",
    "\n",
    "\n",
    "#OCTA\n",
    "# # directory_to_clean=[r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\train',\n",
    "# #                     r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\train_aug',\n",
    "# #                     r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\train_aug_jpeg',\n",
    "# #                     r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\test',\n",
    "# #                     r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\test_png',]\n",
    "\n",
    "# # # 刪除檔案\n",
    "# delete_files_in_directory(*directory_to_clean)\n",
    "\n",
    "# #遞迴刪除資料夾目錄樹\n",
    "# #delete_folder(directory_to_clean) #成功執行，有時候會有莫名的PermissionError，重啟後再執行看看\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "思考如何切割資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立train test folder以及內建子folder nor cal (做一次即可)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories created successfully.\n"
     ]
    }
   ],
   "source": [
    "from create_dir import create_directories\n",
    "#root_dir=r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus'\n",
    "\n",
    "#OCTA\n",
    "root_dir=r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA'\n",
    "create_directories(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目標: 利用NOR1~NOR6 作為train ; NOR7 supra5作為test(不能讓train test同時都含有同一子目錄的data，會有作弊的情形，導致model結果超乎預期的好) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也就是說，我們用train_data來測試不包含在其中的test_data(兩者資料完全不能重複!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不論換哪個資料，都遇到overfitting，copy備份NOR-複製 CAL-複製 & NOR_png-複製 CAL_png-複製 手動刪除可能有問題的data，並用刪除不良影像後的NOR\n",
    "CAL作測試"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAL:del \n",
    "supra1 0-221  supra3 1-501 873-958 supra4:2-9 101-109 111-119 121-129...161-169\n",
    "\n",
    "NOR: NOR7 340-440  NOR2 400-789"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "方便查看還有哪些檔案(怕自己忘記刪除哪幾個)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# folder_path = r\"D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\CAL_png - 複製\"\n",
    "\n",
    "# # 獲取目錄中的所有檔案名\n",
    "# file_names = os.listdir(folder_path)\n",
    "\n",
    "# # 過濾出以\"supra4\"為前綴的檔案並按順序排列\n",
    "# supra4_files = sorted([file for file in file_names if file.startswith(\"supra4\")])\n",
    "\n",
    "# # 列印出符合條件的檔案名\n",
    "# for file in supra4_files:\n",
    "#     print(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把NOR1,NOR2開頭的放test，其他放train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files copied successfully.\n"
     ]
    }
   ],
   "source": [
    "import train_test_split \n",
    "\n",
    "# # 源目录和目标目录\n",
    "# src_nor_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\NOR-複製'\n",
    "# train_nor_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\train\\nor'\n",
    "# test_nor_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\test\\nor'\n",
    "\n",
    "# 源目录和目标目录\n",
    "src_nor_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\NOR'\n",
    "train_nor_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\train\\nor'\n",
    "test_nor_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\test\\nor'\n",
    "\n",
    "train_test_split.split(src_nor_path,train_nor_path,test_nor_path,'NOR1','NOR3')\n",
    "#函式把全部NORcopy到train/nor的資料->所以準確率才100%!->修正函式後成功\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "supra1,supra2 作為test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "遇到module緩存問題，導致之後from train_test_split import split會直接使用上一次執行的結果! importlib清除緩存(沒用!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "考慮使用 train_test_split 模块的命名空间来调用 split :train_test_split.split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "刪除有問題檔案， supra3 :1-500  873-958  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files copied successfully.\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "#from train_test_split import split\n",
    "\n",
    "import train_test_split\n",
    "\n",
    "# # 源目录和目标目录\n",
    "# src_cal_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\CAL-複製'#空格也會影響路徑名\n",
    "# train_cal_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\train\\cal'\n",
    "# test_cal_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\test\\cal'\n",
    "\n",
    "# 源目录和目标目录\n",
    "# src_cal_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\CAL-複製'#空格也會影響路徑名\n",
    "# train_cal_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\train\\cal'\n",
    "# test_cal_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\test\\cal'\n",
    "\n",
    "\n",
    "\n",
    "# 法一.清除模块缓存->無效\n",
    "# importlib.reload(train_test_split)\n",
    "\n",
    "# split(src_cal_path,train_cal_path,test_cal_path,'supra5')\n",
    "\n",
    "\n",
    "# #法二:物件導向\n",
    "# train_test_split.split(src_cal_path,train_cal_path,test_cal_path,'supra6','supra8') #改supra2(比較像異常組織)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "嘗試shuffle train test folder，避免model記住某特定資料順序造成overfitting\n",
    "必做!!! 之後查看tSNE被錯分的影像，可以透過前綴快速找出是第幾張影像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "#如果文件名諱衝突才考慮用此code\n",
    "def shuffle_files_in_folder(folder_path):\n",
    "    # 遍历文件夹中的所有子文件夹\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        # 对每个子文件夹中的文件列表进行随机打乱\n",
    "        random.shuffle(files)\n",
    "        # 对每个文件进行重命名，加上随机数字前缀，以确保文件名的唯一性\n",
    "        for i, file_name in enumerate(files):\n",
    "            src_path = os.path.join(root, file_name)\n",
    "            # 构造新的文件名，加上随机数字前缀，取5位數，因為有幾千筆data\n",
    "            new_file_name = f\"{i:05d}_{file_name}\"\n",
    "            #new_file_name = f\"{file_name}\"   #改成這樣就無法shuffle:why? \n",
    "            dst_path = os.path.join(root, new_file_name)\n",
    "            # 重命名文件\n",
    "            os.rename(src_path, dst_path)\n",
    "            print(f\"Shuffled file: {src_path} -> {dst_path}\")\n",
    "\n",
    "# 示例调用\n",
    "#train_folder = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\train'\n",
    "test_folder = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\test\\nor'\n",
    "#shuffle_files_in_folder(train_folder)\n",
    "shuffle_files_in_folder(test_folder)\n",
    "\n",
    "\n",
    "#OCTA\n",
    "#train_folder = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\train'\n",
    "test_folder = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\test\\nor'\n",
    "#shuffle_files_in_folder(train_folder)\n",
    "shuffle_files_in_folder(test_folder)\n",
    "\n",
    "#shuffle一次即可，不然前綴會一直累計\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把train data aug，看overfitting有沒有改善"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成数据增强并保存至目标文件路径。\n"
     ]
    }
   ],
   "source": [
    "from data_aug import data_augmentation_npy\n",
    "src_paths=[r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\train\\nor',\n",
    "           r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\train\\cal']\n",
    "des_paths=[r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\train_aug\\nor',\n",
    "           r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\train_aug\\cal']\n",
    "\n",
    "#OCTA\n",
    "src_paths=[r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\train\\nor',\n",
    "           r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\train\\cal']\n",
    "des_paths=[r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\train_aug\\nor',\n",
    "           r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\train_aug\\cal']\n",
    "\n",
    "for des_path in des_paths:\n",
    "    os.makedirs(des_path, exist_ok=True)\n",
    "    \n",
    "#由於ImageDataGenerator 类不支持直接保存 .npy，先用save_format='jpeg'再搭配np.save(所以多的jpeg檔要再移到別的folder)\n",
    "data_augmentation_npy(src_paths, des_paths) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先讀取上面的data並省略下面aug的兩步驟，如果overfit的話再考慮"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把aug folder中的jpeg檔移動到另一個名為aug_jpeg的folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有 jpeg 文件已移动到目标文件夹。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# 源文件夹和目标文件夹路径\n",
    "src_folder = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\train_aug'\n",
    "dest_folder = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\train_aug_jpeg'\n",
    "\n",
    "\n",
    "#OCTA\n",
    "# 源文件夹和目标文件夹路径\n",
    "src_folder = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\train_aug'\n",
    "dest_folder = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\train_aug_jpeg'\n",
    "\n",
    "\n",
    "# 创建目标文件夹（如果不存在）\n",
    "os.makedirs(dest_folder, exist_ok=True)\n",
    "\n",
    "# 遍历源文件夹中的子文件夹（cal 和 nor）\n",
    "for subdir in ['cal', 'nor']:\n",
    "    src_subfolder = os.path.join(src_folder, subdir)\n",
    "    dest_subfolder = os.path.join(dest_folder, subdir)\n",
    "\n",
    "    # 创建目标子文件夹（如果不存在）\n",
    "    os.makedirs(dest_subfolder, exist_ok=True)\n",
    "\n",
    "    # 遍历源子文件夹中的所有文件\n",
    "    for file in os.listdir(src_subfolder):\n",
    "        #print(file)\n",
    "        src_file = os.path.join(src_subfolder, file)\n",
    "        #print(src_file)\n",
    "\n",
    "    #     # 检查文件是否为 .jpeg 格式:檔案格式要有完整路徑(故需要os.path.join)\n",
    "        if os.path.isfile(src_file) and src_file.endswith('.jpeg'):\n",
    "            # 移动文件到目标文件夹\n",
    "            shutil.move(src_file, dest_subfolder)\n",
    "\n",
    "print(\"所有 jpeg 文件已移动到目标文件夹。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "讀取data(2nd次執行code時，不用再重新分類，直接讀)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch + concat 大降內存 速度快"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先測試train/test 看model 訓練結果，不行再考慮train_aug/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可考慮用多線程load data，看是否能加速讀取:load_data_with_queue.py/load_data_with_pool.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用函式包住各種data、label生成過程，比較簡潔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\reqiured_funcs\") #存取所需函式的路徑\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st讀data方式 : 把from load_data import npy_batch_data_generator, load_npy_data...到train model之前的所有code包在generate_and_save_data中，快!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels shape: (9370, 1)\n",
      "Test labels shape: (3850, 1)\n"
     ]
    }
   ],
   "source": [
    "import load_save_pkl,os\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     save_dir = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\pkl' # 替换为实际的保存路径\n",
    "#     # 如果日期文件夹不存在，则创建它\n",
    "#     if not os.path.exists(save_dir):\n",
    "#         os.makedirs(save_dir)\n",
    "    \n",
    "#     train_nor_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\train\\nor'\n",
    "#     test_nor_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\test\\nor'\n",
    "#     train_cal_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\train\\cal'\n",
    "#     test_cal_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\test\\cal'\n",
    "\n",
    "#OCTA\n",
    "if __name__ == \"__main__\":\n",
    "    save_dir = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\pkl' # 替换为实际的保存路径\n",
    "    # 如果日期文件夹不存在，则创建它\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    train_nor_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\code\\2024_dc_OCTA\\train\\nor'\n",
    "    test_nor_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\code\\2024_dc_OCTA\\test\\nor'\n",
    "    train_cal_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\code\\2024_dc_OCTA\\train\\cal'\n",
    "    test_cal_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\code\\2024_dc_OCTA\\test\\cal'\n",
    "\n",
    "    load_save_pkl.generate_and_save_data(train_nor_path, train_cal_path, test_nor_path, test_cal_path, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下次直接跳過generate_and_save_data，直接load pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data and labels from pickle file.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import load_save_pkl\n",
    "import os\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     save_dir = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\pkl'  # 替换为实际的保存路径\n",
    "\n",
    "#     try:\n",
    "#         train_data,train_labels,test_data,test_labels = load_save_pkl.load_data_pickle(save_dir, \"data.pkl\")\n",
    "#         print(\"Loaded data and labels from pickle file.\")\n",
    "#     except FileNotFoundError as e:\n",
    "#         print(e)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    save_dir = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\pkl'  # 替换为实际的保存路径\n",
    "\n",
    "    try:\n",
    "        train_data,train_labels,test_data,test_labels = load_save_pkl.load_data_pickle(save_dir, \"data.pkl\")\n",
    "        print(\"Loaded data and labels from pickle file.\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load pkl後記得做one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "#%% one hot encoding\n",
    "train_labels = keras.utils.to_categorical(train_labels, num_classes=2)\n",
    "test_labels  = keras.utils.to_categorical(test_labels, num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd讀data方式(土法煉鋼)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from load_data import npy_batch_data_generator, load_npy_data\n",
    "\n",
    "train_nor_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\train\\nor'\n",
    "test_nor_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\test\\nor'\n",
    "train_cal_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\train\\cal'\n",
    "test_cal_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\test\\cal'\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_folders = [train_nor_path,train_cal_path]\n",
    "    test_folders =  [test_nor_path,test_cal_path]\n",
    "    batch_size = 128 #增加batch，以加快讀取速度\n",
    "    \n",
    "    cal_train_gen, nor_train_gen, cal_test_gen, nor_test_gen = load_npy_data(train_folders, test_folders, batch_size) #在load_data中又會呼叫batch_data_generator\n",
    "\n",
    "    cal_train_data = []\n",
    "    for cal_batch in cal_train_gen:\n",
    "        cal_train_data.append(cal_batch)\n",
    "    cal_train_data = np.concatenate(cal_train_data, axis=0)\n",
    "\n",
    "    nor_train_data = []\n",
    "    for nor_batch in nor_train_gen:\n",
    "        nor_train_data.append(nor_batch)\n",
    "    nor_train_data = np.concatenate(nor_train_data, axis=0)\n",
    "\n",
    "    cal_test_data = []\n",
    "    for cal_batch in cal_test_gen:\n",
    "        cal_test_data.append(cal_batch)\n",
    "    cal_test_data = np.concatenate(cal_test_data, axis=0)\n",
    "\n",
    "    nor_test_data = []\n",
    "    for nor_batch in nor_test_gen:\n",
    "        nor_test_data.append(nor_batch)\n",
    "    nor_test_data = np.concatenate(nor_test_data, axis=0)\n",
    "\n",
    "    #比原來data總數少一些! why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "跑完發現len(train_data)<len(test_data)，會有overfit問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "刪除多餘變量，不佔內存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "當訓練model發現overfit時想重做，restart kernel把過多變量格式化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__name__', '__doc__', '__package__', '__loader__', '__spec__', '__builtin__', '__builtins__', '_ih', '_oh', '_dh', 'In', 'Out', 'get_ipython', 'exit', 'quit', 'open', '_', '__', '___', '__cached__', '_importable', 'user_specific_imports', '_imports', 'LazyImport', 'pd', 'np', 'dd', 'SparkContext', 'load_workbook', 'open_workbook', 'wr', 'mpl', 'plt', 'sns', 'py', 'go', 'px', 'dash', 'bokeh', 'alt', 'pydot', 'cv2', 'skimage', 'Image', 'imutils', 'statistics', 'stats', 'sm', 'fbprophet', 'Prophet', 'ARIMA', 'sklearn', 'LinearRegression', 'LogisticRegression', 'Lasso', 'LassoCV', 'Ridge', 'RidgeCV', 'ElasticNet', 'ElasticNetCV', 'PolynomialFeatures', 'StandardScaler', 'MinMaxScaler', 'RobustScaler', 'OneHotEncoder', 'LabelEncoder', 'TSNE', 'PCA', 'SimpleImputer', 'train_test_split', 'cross_val_score', 'GridSearchCV', 'RandomizedSearchCV', 'KFold', 'StratifiedKFold', 'svm', 'GradientBoostingClassifier', 'GradientBoostingRegressor', 'RandomForestClassifier', 'RandomForestRegressor', 'TfidfVectorizer', 'CountVectorizer', 'metrics', 'sg', 'KMeans', 'xgb', 'lgb', 'tf', 'keras', 'torch', 'fastai', 'nltk', 'spacy', 're', 'textblob', 'sys', 'os', 'glob', 'Path', 'pickle', 'dt', 'tqdm', 'lazy_imports', 'active_imports', 'utils', 'get_user_symbols', 'install_extensions', 'install_nbextension', 'install_labextension', 'user_symbols', 'pyforest', '_i', '_ii', '_iii', '_i1', '_i2', 'load_npy_data', 'cal_train_data', '_i3', 'nor_train_data', 'cal_test_data', 'nor_test_data', '_i4', 'current_module', 'strings_to_drop', 'var_name']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# 获取当前全局变量字典\n",
    "current_module = sys.modules[__name__]\n",
    "\n",
    "# 定义要刪除的字符串\n",
    "strings_to_drop = ['batch','file','path','folder','gen']\n",
    "\n",
    "\n",
    "# 删除不需要的变量\n",
    "for var_name in list(current_module.__dict__.keys()):\n",
    "    if  any(s in var_name for s in strings_to_drop):\n",
    "        del current_module.__dict__[var_name]\n",
    "\n",
    "# 现在只剩下需要的变量\n",
    "print(list(current_module.__dict__.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "跑stack會當機->之後想怎麼解決"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "內存不足所導致(可在tf環境打nvidia-smi查看)，分batch處理："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "方案二：Memory-Mapped Files(內存映射文件) :成功而且code相對簡單"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有效地減輕RAM負擔，數據存儲在磁盤上，並通過內存映射將數據的小片段加載到RAM，而不是一次性將整個數據集加載到RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to memory-mapped files:與code存取於相同的目錄\n",
    "np.save('cal_train_data.npy', cal_train_data)\n",
    "np.save('nor_train_data.npy', nor_train_data)\n",
    "np.save('cal_test_data.npy', cal_test_data)\n",
    "np.save('nor_test_data.npy', nor_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若已經存在正確的npy檔，下次直接加載即可(不是的話np.save npy的部分也要做)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data as memory-mapped files\n",
    "cal_train_data = np.load('cal_train_data.npy', mmap_mode='r')\n",
    "nor_train_data = np.load('nor_train_data.npy', mmap_mode='r')\n",
    "cal_test_data = np.load('cal_test_data.npy', mmap_mode='r')\n",
    "nor_test_data = np.load('nor_test_data.npy', mmap_mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 224, 224, 3)\n",
      "(1792, 224, 224, 3)\n",
      "(2816, 224, 224, 3)\n",
      "(1024, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(cal_train_data.shape)\n",
    "print(nor_train_data.shape) #原來為2968\n",
    "\n",
    "print(cal_test_data.shape)  #原:1866\n",
    "print(nor_test_data.shape)  #原:1874"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6912, 224, 224, 3)\n",
      "(2816, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#train and test data\n",
    "train_data = np.vstack((cal_train_data,nor_train_data))\n",
    "test_data = np.vstack((cal_test_data,nor_test_data))\n",
    "\n",
    "#cal & nor data\n",
    "cal_data = np.vstack((cal_train_data,cal_test_data))\n",
    "nor_data = np.vstack((nor_train_data,nor_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train sequence random shuffle\n",
    "#shuffle pros: 1.improved generalization 2.avoid overfitting \n",
    "import random\n",
    "\n",
    "train_seq = (np.arange(0,np.size(train_data,0),1)) #公差1之seq  #\n",
    "random.shuffle(train_seq)\n",
    "train_data = train_data[train_seq,:,:]\n",
    "\n",
    "#train_seq可能有無效index，超過train_labels範圍，造成out of bound!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels shape: (6912, 1)\n",
      "Test labels shape: (2816, 1)\n"
     ]
    }
   ],
   "source": [
    "cal_train_upto=4096\n",
    "nor_train_upto=2816\n",
    "\n",
    "# create label \n",
    "cal_labels=np.ones((np.size(cal_data,0),1))\n",
    "nor_labels = np.zeros((np.size(nor_data,0),1))\n",
    "\n",
    "# split label\n",
    "cal_train_labels, cal_test_labels = cal_labels[:cal_train_upto], cal_labels[cal_train_upto:]\n",
    "nor_train_labels, nor_test_labels = nor_labels[:nor_train_upto], nor_labels[nor_train_upto:]\n",
    "\n",
    "# merge label \n",
    "train_labels = np.vstack((cal_train_labels,nor_train_labels))\n",
    "test_labels = np.vstack((cal_test_labels,nor_test_labels))\n",
    "\n",
    "# #因應OutOfBound得下兩段code\n",
    "# # 生成随机打乱顺序的索引\n",
    "# train_seq = np.random.permutation(len(train_labels))\n",
    "\n",
    "# # 确保 train_seq 的最大索引值在 train_labels 的范围内\n",
    "# if np.max(train_seq) >= len(train_labels):\n",
    "#     raise ValueError(f\"train_seq contains out-of-bounds indices: max index {np.max(train_seq)}, train_labels size {len(train_labels)}\")\n",
    "\n",
    "# random shuffle\n",
    "train_labels = train_labels[train_seq]\n",
    "\n",
    "print(\"Train labels shape:\", train_labels.shape)\n",
    "print(\"Test labels shape:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__name__', '__doc__', '__package__', '__loader__', '__spec__', '__builtin__', '__builtins__', '_ih', '_oh', '_dh', 'In', 'Out', 'get_ipython', 'exit', 'quit', 'open', '_', '__', '___', '__cached__', '_importable', 'user_specific_imports', '_imports', 'LazyImport', 'pd', 'np', 'dd', 'SparkContext', 'load_workbook', 'open_workbook', 'wr', 'mpl', 'plt', 'sns', 'py', 'go', 'px', 'dash', 'bokeh', 'alt', 'pydot', 'cv2', 'skimage', 'Image', 'imutils', 'statistics', 'stats', 'sm', 'fbprophet', 'Prophet', 'ARIMA', 'sklearn', 'LinearRegression', 'LogisticRegression', 'Lasso', 'LassoCV', 'Ridge', 'RidgeCV', 'ElasticNet', 'ElasticNetCV', 'PolynomialFeatures', 'OneHotEncoder', 'LabelEncoder', 'TSNE', 'PCA', 'SimpleImputer', 'train_test_split', 'cross_val_score', 'GridSearchCV', 'RandomizedSearchCV', 'KFold', 'StratifiedKFold', 'svm', 'GradientBoostingClassifier', 'GradientBoostingRegressor', 'RandomForestClassifier', 'RandomForestRegressor', 'TfidfVectorizer', 'CountVectorizer', 'metrics', 'sg', 'KMeans', 'xgb', 'lgb', 'tf', 'keras', 'torch', 'fastai', 'nltk', 'spacy', 're', 'textblob', 'sys', 'os', 'glob', 'Path', 'pickle', 'dt', 'tqdm', 'lazy_imports', 'active_imports', 'utils', 'get_user_symbols', 'install_extensions', 'install_nbextension', 'install_labextension', 'user_symbols', 'pyforest', '_i', '_ii', '_iii', '_i1', '_i2', 'load_npy_data', '_i3', '_i4', 'current_module', 'strings_to_drop', 'var_name', '_i5', '_i6', '_i7', '_i8', 'train_data', 'test_data', '_i9', 'random', '_i10', 'train_labels', 'test_labels', '_i11', '_i12']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# 获取当前全局变量字典\n",
    "current_module = sys.modules[__name__]\n",
    "\n",
    "# 定义要保留的字符串\n",
    "strings_to_drop = ['cal','nor','seq']\n",
    "\n",
    "# 删除不需要的变量\n",
    "for var_name in list(current_module.__dict__.keys()):\n",
    "    if  any(s in var_name for s in strings_to_drop):\n",
    "        del current_module.__dict__[var_name]\n",
    "\n",
    "# 现在只剩下需要的变量:test_data test_labels train_data train_labels\n",
    "print(list(current_module.__dict__.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import keras'); }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import keras'); }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%% one hot encoding\n",
    "train_labels = keras.utils.to_categorical(train_labels, num_classes=2)\n",
    "test_labels  = keras.utils.to_categorical(test_labels, num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用train/test data出現overfit ->改用train_aug/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "存取model的路徑要記得改->看是跑SD-OCT 還是OCTA並動態調整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50, VGG16,NASNetMobile\n",
    "from keras.layers import Input, Flatten, Dense,Dropout,concatenate,Conv2D, MaxPooling2D, AvgPool2D,Add\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop, Adagrad,SGD,Adam\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "from keras.callbacks import Callback,EarlyStopping\n",
    "\n",
    "# 定义早停法\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "callback=Callback()\n",
    "\n",
    "\n",
    "ind=0.7  #acc不到0.8，沒存model\n",
    "start_time=time.time()\n",
    "num_epoch=10\n",
    "####### 定义权重分配比例################\n",
    "resnet_weight = 0.5\n",
    "vgg_weight = 0.5\n",
    "#nas_weight=0.5\n",
    "\n",
    "#符號多部分就是要調整的部分\n",
    "\n",
    "#一次3個model就會crash!\n",
    "# 创建 ResNet50 模型实例，include_top=False 表示不包含顶部的全连接层\n",
    "resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "# # 创建 VGG16 模型实例，include_top=False 表示不包含顶部的全连接层\n",
    "vgg = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "# 创建 NASNetMobile 模型实例，include_top=False 表示不包含顶部的全连接层\n",
    "nas = NASNetMobile(weights='imagenet', include_top=False, input_shape=(224, 224, 3)) #non-ideal choice\n",
    "\n",
    "\n",
    "# 将 ResNet50 模型作为一个层添加到 ensemble 模型中，並進行加權\n",
    "resnet_output = resnet.output\n",
    "resnet_output = Flatten()(resnet_output)#可添加dropout在後\n",
    "resnet_output=Dropout(0.2)(resnet_output)\n",
    "resnet_output = Dense(256, activation='relu')(resnet_output)*resnet_weight\n",
    "\n",
    "# 将 VGG16 模型作为一个层添加到 ensemble 模型中，並進行加權\n",
    "vgg_output = vgg.output\n",
    "vgg_output = Flatten()(vgg_output) #可添加dropout在後\n",
    "vgg_output=Dropout(0.2)(vgg_output)\n",
    "vgg_output = Dense(256, activation='relu')(vgg_output)*vgg_weight\n",
    "\n",
    "# 将 NASNetMobile 模型作为一个层添加到 ensemble 模型中，並進行加權\n",
    "nas_output = nas.output\n",
    "nas_output = Flatten()(nas_output)\n",
    "#nas_output = Dense(256, activation='relu')(nas_output)*nas_weight\n",
    "\n",
    "########### 合并两个模型的输出 : 依照自己要的output客製化增減####################\n",
    "merged_output = concatenate([resnet_output,vgg_output])\n",
    "\n",
    "# 添加自定义的分类层\n",
    "predictions = Dense(2, activation='sigmoid')(merged_output)\n",
    "\n",
    "########### 创建 ensemble 模型####################\n",
    "ensemble_model = Model(inputs=[resnet.input,vgg.input], outputs=predictions)\n",
    "\n",
    "# 编译 ensemble 模型\n",
    "ensemble_model.compile(optimizer=SGD(lr=1e-3), loss='binary_crossentropy', metrics=['accuracy']) \n",
    "#SGD不佳:可以嘗試Adagrad Adam Momentum\n",
    "\n",
    "# 存储每个epoch的训练准确率、验证准确率和测试准确率\n",
    "train_loss_history = []\n",
    "valid_loss_history = []\n",
    "test_loss_history = []\n",
    "\n",
    "# 存储每个epoch的训练准确率、验证准确率和测试准确率\n",
    "train_accuracy_history = []\n",
    "valid_accuracy_history = []\n",
    "test_accuracy_history = []\n",
    "##不能定義在loop內部!不然每次都會重置##\n",
    "\n",
    "# 設置計數器以檢查連續epoch中的精度提升\n",
    "no_improvement_count = 0\n",
    "max_no_improvement = 5  # 定義最大不提升次數\n",
    "\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "\n",
    "    ############# 训练 ensemble 模型，传递相同的数据给两个模型####################\n",
    "    history=ensemble_model.fit([train_data, train_data], train_labels, batch_size=16, epochs=1, validation_split=0.2, verbose=1,callbacks=[early_stopping,callback])\n",
    "    #batch_size太小會有震盪問題!\n",
    "\n",
    "    # 记录训练损失\n",
    "    train_loss = history.history['loss'][-1]\n",
    "    train_loss_history.append(train_loss)\n",
    "\n",
    "    # 记录验证损失\n",
    "    valid_loss = history.history['val_loss'][-1]\n",
    "    valid_loss_history.append(valid_loss)\n",
    "\n",
    "    # 记录训练准确率\n",
    "    train_accuracy = history.history['accuracy'][-1]\n",
    "    train_accuracy_history.append(train_accuracy)\n",
    "\n",
    "    # 记录验证准确率\n",
    "    valid_accuracy = history.history['val_accuracy'][-1]\n",
    "    valid_accuracy_history.append(valid_accuracy)\n",
    "\n",
    "    ############## 进行预测并计算准确率##################\n",
    "    loss, acc = ensemble_model.evaluate([test_data,test_data], test_labels) #expect 2 inputs! -> [test_data,test_data]\n",
    "\n",
    "    # 保存测试损失\n",
    "    test_loss_history.append(loss)\n",
    "\n",
    "    # 保存测试准确率\n",
    "    test_accuracy_history.append(acc)\n",
    "\n",
    "    # 檢查是否有精度提升，如果沒有，增加計數器\n",
    "    if acc <= ind:\n",
    "        no_improvement_count += 1\n",
    "    else:\n",
    "        no_improvement_count = 0\n",
    "    \n",
    "    # 如果連續epoch中沒有提升，則結束迴圈\n",
    "    if no_improvement_count >= max_no_improvement:\n",
    "        print(f'No improvement for {max_no_improvement} epochs. Stopping training.')\n",
    "        break\n",
    "\n",
    "    # 如果准确率更高，保存模型\n",
    "    if acc > ind:\n",
    "        ind = acc\n",
    "\n",
    "        # 将模型保存到指定目录\n",
    "        best_model_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\best_results'\n",
    "\n",
    "        # OCTA\n",
    "        best_model_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\best_results'\n",
    "\n",
    "\n",
    "        if not os.path.exists(best_model_path):\n",
    "            os.makedirs(best_model_path)\n",
    "                # 创建日期子目录\n",
    "        today_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        save_dir = os.path.join(best_model_path, today_date)\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        #記得改檔名\n",
    "        model_filename = 'ensemble_ResNet50_{}_&VGG16_{}_SGD_acc={}.h5'.format(resnet_weight,vgg_weight,round(acc,4))\n",
    "        ensemble_model.save(os.path.join(save_dir, model_filename)) \n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epoch}, Test Accuracy: {acc}')  #epoch+1 的目的:略過初始的超大val_loss?\n",
    "\n",
    "\n",
    "    # 计算并输出训练时间\n",
    "    model_training_time = time.time() - start_time\n",
    "    minutes, seconds = divmod(model_training_time, 60)\n",
    "    print(f\"Training time: {int(minutes)} min and {round(seconds, 4)} sec\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "跑完後明天測試tSNE是否可以正常顯示圖片"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練中途interrupt，最好關閉重開code，以免大量var佔內存，在跑np.stack那邊當機"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下次可以直接load model 不用重新訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%load model : 從日期那邊微調路徑!\n",
    "from keras.models import load_model\n",
    "\n",
    "# 指定模型檔案路徑:記得從日期那邊微調路徑!\n",
    "model_path = r\"D:/OCT/dental OCT/bare tooth/ensemble_model_aug/best_results/2024-05-22/ensemble_ResNet50_0.5_&VGG16_0.5_SGD_acc=0.7919.h5\"\n",
    "\n",
    "#OCTA\n",
    "model_path = r\"D:/OCT/dental OCT/bare tooth/ensemble_model_aug/code/2024_dc_OCTA/best_results/2024-05-22/ensemble_ResNet50_0.5_&VGG16_0.5_SGD_acc=0.7919.h5\"\n",
    "\n",
    "\n",
    "# 載入模型\n",
    "ensemble_model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.csdn.net/ytusdc/article/details/107738749 調參website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 定义保存路径\n",
    "save_dir = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\loss_fig'\n",
    "\n",
    "# OCTA\n",
    "save_dir = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\loss_fig'\n",
    "\n",
    "# 创建日期子目录\n",
    "today_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "save_dir = os.path.join(save_dir, today_date)\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "\n",
    "############### 构建保存文件路径################\n",
    "# 构建保存文件路径 : 依據不同的optimizer命名fig\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") #確保每次存取都有唯一名，不要覆蓋上次存取的圖\n",
    "save_path = os.path.join(save_dir, f'ResNet50_{resnet_weight}&VGG16_{vgg_weight}_with_SGD(lr=1e-3)_loss_fig_{timestamp}.png')\n",
    "\n",
    "# 截斷 train_loss_history 和 valid_loss_history 以使其長度相同 : 因為中間有Early_stop機制，會造成train_loss_history 和 valid_loss_history 的形狀不匹配使得圖出不來!\n",
    "min_length = min(len(train_loss_history), len(valid_loss_history))\n",
    "\n",
    "# 繪製损失隨 epoch 變化的曲线\n",
    "plt.figure(figsize=(10, 6)) \n",
    "plt.plot(range(2, min_length + 2), train_loss_history, 'r-', label='Train Loss')\n",
    "plt.plot(range(2, min_length + 2), valid_loss_history, 'b-', label='Validation Loss')\n",
    "plt.title('Loss vs. Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout() #自動調整圖的佈局，以確保軸標籤不被截斷\n",
    "\n",
    "\n",
    "# 標示 y 座標數值\n",
    "for i, loss in enumerate(train_loss_history[:min_length+1]):\n",
    "    plt.text(i+2, loss, f'{loss:.4f}', fontsize=15, ha='center', va='bottom', color='red')\n",
    "\n",
    "for i, loss in enumerate(valid_loss_history[:min_length+1]):\n",
    "    plt.text(i+2, loss, f'{loss:.4f}', fontsize=15, ha='center', va='bottom', color='blue')\n",
    "\n",
    "\n",
    "plt.savefig(save_path)\n",
    "plt.show()\n",
    "\n",
    "#圖不完整變成要手動存!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "標數值在圖上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the save directory\n",
    "save_dir = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\acc_fig'\n",
    "\n",
    "#OCTA\n",
    "save_dir = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\acc_fig'\n",
    "\n",
    "\n",
    "# Create a subdirectory for the current date\n",
    "today_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "save_dir = os.path.join(save_dir, today_date)\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "\n",
    "# Build the save file path : 記得改檔名\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "save_path = os.path.join(save_dir, f'ResNet50_{resnet_weight}&VGG16_{vgg_weight}_with_SGD(lr=1e-3)_acc_fig_{timestamp}.png')\n",
    "\n",
    "# 截斷 train_loss_history 和 valid_loss_history 以使其長度相同 : 因為中間有Early_stop機制，造成train_loss_history 和 valid_loss_history 的形狀不匹配!\n",
    "min_length = min(len(train_accuracy_history), len(valid_accuracy_history),len(test_accuracy_history))\n",
    "\n",
    "\n",
    "# 繪製损失隨 epoch 變化的曲线\n",
    "# Plot accuracy vs. epoch\n",
    "plt.figure(figsize=(10, 6))  # 設置圖片尺寸為寬度10英寸，高度6英寸\n",
    "plt.plot(range(2, min_length+2), train_accuracy_history,'r', label='Train Accuracy')\n",
    "plt.plot(range(2, min_length+2), valid_accuracy_history,'g', label='Validation Accuracy')\n",
    "plt.plot(range(2, min_length+2), test_accuracy_history,'b', label='Test Accuracy')\n",
    "plt.title('Accuracy vs. Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right') #調整圖例位置\n",
    "plt.grid(True)\n",
    "plt.tight_layout() #自動調整圖的佈局，以確保軸標籤不被截斷\n",
    "\n",
    "\n",
    "# Annotate each point with its accuracy value : 順序要放對(放中間)! 放最下面會失敗\n",
    "# xytext : 移動數值位置座標 -> 沒辦法到很精準 ------------------------------------------>捨棄改用plt.text!!!\n",
    "# for i, acc in enumerate(train_accuracy_history[:min_length+1]):\n",
    "#     plt.annotate(f'{acc:.4f}', (i+2, acc), textcoords=\"offset points\", xytext=(0,15), ha='center')\n",
    "\n",
    "# for i, acc in enumerate(valid_accuracy_history[:min_length+1]):\n",
    "#     plt.annotate(f'{acc:.4f}', (i+2, acc), textcoords=\"offset points\", xytext=(0,-10), ha='center')  # xytext : 移動數值位置座標\n",
    "\n",
    "# for i, acc in enumerate(test_accuracy_history[:min_length+1]):\n",
    "#     plt.annotate(f'{acc:.4f}', (i+2, acc), textcoords=\"offset points\", xytext=(0,15), ha='center')\n",
    "\n",
    "# 標示 y 座標數值\n",
    "for i, acc in enumerate(train_accuracy_history[:min_length+1]):\n",
    "    plt.text(i+2, acc, f'{acc:.4f}', fontsize=15, ha='center', va='top', color='red')  #注意數值位置改為top!\n",
    "\n",
    "for i, acc in enumerate(valid_accuracy_history[:min_length+1]):\n",
    "    plt.text(i+2, acc, f'{acc:.4f}', fontsize=15, ha='center', va='bottom', color='green')\n",
    "\n",
    "for i, acc in enumerate(test_accuracy_history[:min_length+1]):\n",
    "    plt.text(i+2, acc, f'{acc:.4f}', fontsize=15, ha='center', va='bottom', color='blue')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(save_path)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% expected shape :(103,142,1)\n",
    "prediction = ensemble_model.predict([test_data,test_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%plot model\n",
    "from keras.utils import plot_model\n",
    "plot_model(ensemble_model, to_file='model.png')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#如何同時呈現不同權重時的ROC_curve?\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# 假设 C 是您的混淆矩阵\n",
    "spe = [] #specificity\n",
    "sen = [] #sensitivity   \n",
    "tar = 0\n",
    "for i in range(test_labels.shape[0]):\n",
    "    p = 1*(prediction[:,1] < prediction[i,1])\n",
    "    t = np.argmax(test_labels, axis=1)\n",
    "    C = confusion_matrix(p, t)  # 举例的混淆矩阵\n",
    "    CC = np.sum(C, axis=0)\n",
    "    NC = C / CC  # Normalized C\n",
    "    spe = np.concatenate((spe, [NC[1,1]]))\n",
    "    sen = np.concatenate((sen, [NC[0,0]]))\n",
    "    tarn = C[0,1]+C[1,0]\n",
    "    if tarn>tar:\n",
    "        tar = tarn\n",
    "        thresh = prediction[i,1]\n",
    "spe = np.concatenate((spe, [0, 1]))\n",
    "sen = np.concatenate((sen, [1, 0]))\n",
    "print(spe)\n",
    "print(sen)\n",
    "\n",
    "# Define the save directory\n",
    "save_dir = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\ROC'\n",
    "\n",
    "# OCTA\n",
    "save_dir = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\ROC'\n",
    "\n",
    "# Create a subdirectory for the current date\n",
    "today_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "save_dir = os.path.join(save_dir, today_date)\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "\n",
    "\n",
    "# Build the save file path\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "save_path = os.path.join(save_dir, f'ResNet50_{resnet_weight}&VGG16_{vgg_weight}_SGD(1e-3).png')\n",
    "\n",
    "#%% \n",
    "print(plt.style.available)\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "plt.figure(figsize=(10, 6))  # 設置圖片尺寸為寬度10英寸，高度6英寸(不然fig太小)\n",
    "plt.style.use('_mpl-gallery')\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"    #rcParams : designate picture pixels\n",
    "plt.rcParams[\"axes.titlepad\"] = 15\n",
    "plt.plot(sorted(sen),sorted(1-spe),'b.-')\n",
    "#plt.scatter(sen,1-spe)\n",
    "plt.title('ROC curve', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('1-Specificity', size = 16)\n",
    "plt.ylabel('Sensitivity', size = 16)\n",
    "plt.ylim(-.0, 1)\n",
    "plt.xlim(-.0, 1)\n",
    "\n",
    "# 计算 AUC 面积 :記得sorted! 因為是按照數值趨勢去畫圖\n",
    "roc_auc = auc(sorted(sen), sorted(1 - spe))\n",
    "# 在图上标注 AUC 面积的数值 : 有順序性，所以等圖出來再標示數值\n",
    "plt.text(0.6, 0.2, f'AUC = {roc_auc:.2f}', fontsize=40, fontweight='bold', color='red',ha='center', va='center')\n",
    "\n",
    "plt.tight_layout() #自動調整圖的佈局，以確保軸標籤不被截斷，以確保軸標籤不被截斷\n",
    "plt.savefig(save_path)  #預設dpi大小為100\n",
    "plt.show()\n",
    "\n",
    "#沒辦法code存，只好先手動存!! ->plt.tight_layout() #自動調整圖的佈局，以確保軸標籤不被截斷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 假设 C 是您的混淆矩阵\n",
    "p = np.argmax(prediction, axis=1)\n",
    "t = np.argmax(test_labels, axis=1)\n",
    "C = confusion_matrix(p, t)  # 举例的混淆矩阵\n",
    "\n",
    "CC = np.sum(C, axis=0)\n",
    "NC = C / CC  # Normalized C\n",
    "\n",
    "\n",
    "# Define the save directory\n",
    "save_dir = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\confusion_M'\n",
    "\n",
    "# OCTA\n",
    "save_dir = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\confusion_M'\n",
    "\n",
    "\n",
    "# Create a subdirectory for the current date\n",
    "today_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "save_dir = os.path.join(save_dir, today_date)\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Build the save file path\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "save_path = os.path.join(save_dir, f'ResNet50_{resnet_weight}&VGG16_{vgg_weight}_SGD(1e-3)_normalized_{timestamp}.png')\n",
    "\n",
    "\n",
    "\n",
    "# 绘制归一化混淆矩阵\n",
    "#plt.subplot(121)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(NC, interpolation='nearest', cmap=plt.cm.Blues, extent=(-0.5, len(NC) - 0.5, len(NC) - 0.5, -0.5))\n",
    "plt.title('Normalized confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.grid(False)\n",
    "\n",
    "\n",
    "# 添加文本标签(也就是cal nor 數量)到归一化混淆矩阵\n",
    "thresh = NC.max() / 2.\n",
    "for i in range(len(NC)):\n",
    "    for j in range(len(NC[0])):\n",
    "        plt.text(j, i, format(NC[i, j], '.2f'),  #normalize取到小數點後2位: .2f\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if NC[i, j] > thresh else \"black\",\n",
    "                 fontsize=20,  # 调整字体大小\n",
    "                 fontweight='bold')  # 调整字体粗细\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Build the save file path\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "save_path = os.path.join(save_dir, f'ResNet50_{resnet_weight}&VGG16_{vgg_weight}_SGD(1e-3)_{timestamp}.png')\n",
    "#檔名記得隨optimizer的不同，動態修改\n",
    "\n",
    "\n",
    "# 绘制混淆矩阵\n",
    "#plt.subplot(122)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(C, interpolation='nearest', cmap=plt.cm.Blues, extent=(-0.5, len(C) - 0.5, len(C) - 0.5, -0.5))\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.grid(False)\n",
    "\n",
    "# 添加文本标签(也就是cal nor 數量)到混淆矩阵\n",
    "thresh = C.max() / 2.\n",
    "for i in range(len(C)):\n",
    "    for j in range(len(C[0])):\n",
    "        plt.text(j, i, format(C[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if C[i, j] > thresh else \"black\",\n",
    "                 fontsize=20,  \n",
    "                 fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#cal_test:896 nor_test:960\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perplexity調小後，資料點較分散"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1.加載圖像：從指定的文件夾中加載圖像，分別為 cal_folder 和 nor_folder。\n",
    "2.確定圖像的真實標籤：通過文件夾的名稱來確定每張圖像的True Label，如果圖像位於 cal_folder 中，則將其標籤設置為 'cal'，如果位於 nor_folder 中，則將其標籤設置為 'nor'。\n",
    "3.計算預測標籤：使用模型對測試數據進行預測，並根據預測結果獲取每個數據點的預測標籤。\n",
    "4.生成 t-SNE 圖表：使用 t-SNE 對中間層輸出進行降維，然後根據真實標籤將數據分組，並在圖表中顯示各組的數據點。\n",
    "5.顯示圖像與標籤：根據圖像的真實標籤，在 t-SNE 圖表中對應的數據點上顯示相應的圖像和標籤。\n",
    "6.將 t-SNE 圖表轉換為 HTML：將生成的 t-SNE 圖表轉換為 HTML 字符串。\n",
    "7.保存 HTML 文件：將生成的 HTML 字符串保存為 HTML 文件。\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True label:看圖 Predicted label: 看資料點"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chatgpt下指令突破點:\n",
    "現在你知道真實影像的來源，那請幫我在combined_labels = [f'{tooltips[i]}<br>True Label: {true_labels_group[i]}<br>Predicted Label: {layer_output_label_predict[i]}' for i in range(len(group))] 這段，針對真實影像顯示出正確的<br>True Label: {true_labels_group[i]}，若影像是來自於cal_folder = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\test_png\\cal' ，<br>True Label: {true_labels_group[i]} 要顯示cal，若影像是來自於cal_folder = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\test_png\\nor' ，<br>True Label: {true_labels_group[i]} 要顯示nor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最新改版:試試看  解決資料點跟Predicted label的矛盾，但實際影像為cal，應該設定為True label:cal  True \n",
    "label要跟oct影像互相對應! 差此步->成功!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "透過以下函式查看plot_and_save_tSNE中的layer_name(最後一層的layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('input_4', <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x0000019FCA8746A0>), ('conv1_pad', <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000001A46105EEB0>), ('conv1_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A683754280>), ('conv1_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A6837545E0>), ('conv1_relu', <tensorflow.python.keras.layers.core.Activation object at 0x000001A6837956A0>), ('pool1_pad', <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000001A6837952B0>), ('pool1_pool', <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000001A683498850>), ('conv2_block1_1_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A6834987F0>), ('conv2_block1_1_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A683498E80>), ('conv2_block1_1_relu', <tensorflow.python.keras.layers.core.Activation object at 0x000001A683493F70>), ('conv2_block1_2_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A683493AF0>), ('conv2_block1_2_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A683493AC0>), ('conv2_block1_2_relu', <tensorflow.python.keras.layers.core.Activation object at 0x000001A68349E310>), ('conv2_block1_0_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A68349E640>), ('conv2_block1_3_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A68349E610>), ('conv2_block1_0_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A6837408E0>), ('conv2_block1_3_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A6837401C0>), ('conv2_block1_add', <tensorflow.python.keras.layers.merge.Add object at 0x000001A6837400A0>), ('conv2_block1_out', <tensorflow.python.keras.layers.core.Activation object at 0x000001A68348C640>), ('conv2_block2_1_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A683740F70>), ('conv2_block2_1_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A46105EEE0>), ('conv2_block2_1_relu', <tensorflow.python.keras.layers.core.Activation object at 0x0000019FB17B9460>), ('conv2_block2_2_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000019FA71F1190>), ('conv2_block2_2_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A68348CF10>), ('conv2_block2_2_relu', <tensorflow.python.keras.layers.core.Activation object at 0x000001A67C5E8E50>), ('conv2_block2_3_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A67C5E8640>), ('conv2_block2_3_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A67C5D5820>), ('conv2_block2_add', <tensorflow.python.keras.layers.merge.Add object at 0x0000019FC82946D0>), ('conv2_block2_out', <tensorflow.python.keras.layers.core.Activation object at 0x0000019FC8294130>), ('conv2_block3_1_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000019FC8294250>), ('conv2_block3_1_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000019FC8294040>), ('conv2_block3_1_relu', <tensorflow.python.keras.layers.core.Activation object at 0x0000019FB17E7C40>), ('conv2_block3_2_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000019FB17E7850>), ('conv2_block3_2_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000019FB17E7820>), ('conv2_block3_2_relu', <tensorflow.python.keras.layers.core.Activation object at 0x0000019FBB7896D0>), ('conv2_block3_3_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000019FBB7895B0>), ('conv2_block3_3_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000019FBB789070>), ('conv2_block3_add', <tensorflow.python.keras.layers.merge.Add object at 0x0000019FB17C6760>), ('conv2_block3_out', <tensorflow.python.keras.layers.core.Activation object at 0x0000019FB17C6910>), ('conv3_block1_1_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000019FB17C61F0>), ('conv3_block1_1_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000019FB17C6D30>), ('conv3_block1_1_relu', <tensorflow.python.keras.layers.core.Activation object at 0x0000019FC15EEE80>), ('conv3_block1_2_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000019FC15EEDF0>), ('conv3_block1_2_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000019FB17C1D60>), ('conv3_block1_2_relu', <tensorflow.python.keras.layers.core.Activation object at 0x0000019FC17A26D0>), ('conv3_block1_0_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000019FC17A2E80>), ('conv3_block1_3_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000019FC17A2C10>), ('conv3_block1_0_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000019FC17A2760>), ('conv3_block1_3_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000019FC8270A00>), ('conv3_block1_add', <tensorflow.python.keras.layers.merge.Add object at 0x0000019FC8270B80>), ('conv3_block1_out', <tensorflow.python.keras.layers.core.Activation object at 0x0000019FC82708E0>), ('conv3_block2_1_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000019FC8270700>), ('conv3_block2_1_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000019FC8270070>), ('conv3_block2_1_relu', <tensorflow.python.keras.layers.core.Activation object at 0x0000019FC82F9A30>), ('conv3_block2_2_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000019FC82F96A0>), ('conv3_block2_2_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000019FC82F93A0>), ('conv3_block2_2_relu', <tensorflow.python.keras.layers.core.Activation object at 0x000001A461129730>), ('conv3_block2_3_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A461129160>), ('conv3_block2_3_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A461129490>), ('conv3_block2_add', <tensorflow.python.keras.layers.merge.Add object at 0x000001A461129040>), ('conv3_block2_out', <tensorflow.python.keras.layers.core.Activation object at 0x000001A461136880>), ('conv3_block3_1_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A4611290A0>), ('conv3_block3_1_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A461136F70>), ('conv3_block3_1_relu', <tensorflow.python.keras.layers.core.Activation object at 0x000001A6852AFDF0>), ('conv3_block3_2_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A6852AFF40>), ('conv3_block3_2_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A6852AFDC0>), ('conv3_block3_2_relu', <tensorflow.python.keras.layers.core.Activation object at 0x000001A683511940>), ('conv3_block3_3_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A683511A90>), ('conv3_block3_3_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A683511D90>), ('conv3_block3_add', <tensorflow.python.keras.layers.merge.Add object at 0x000001A68350A490>), ('conv3_block3_out', <tensorflow.python.keras.layers.core.Activation object at 0x000001A68350A5E0>), ('conv3_block4_1_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A68350A730>), ('conv3_block4_1_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A68350ACA0>), ('conv3_block4_1_relu', <tensorflow.python.keras.layers.core.Activation object at 0x000001A68350ADF0>), ('conv3_block4_2_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A68350AD90>), ('conv3_block4_2_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A6835017F0>), ('conv3_block4_2_relu', <tensorflow.python.keras.layers.core.Activation object at 0x000001A683501CA0>), ('conv3_block4_3_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A683501DF0>), ('conv3_block4_3_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A683501F40>), ('conv3_block4_add', <tensorflow.python.keras.layers.merge.Add object at 0x000001A68350B7F0>), ('conv3_block4_out', <tensorflow.python.keras.layers.core.Activation object at 0x000001A68350B940>), ('conv4_block1_1_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A68350BA90>), ('conv4_block1_1_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A68350BDF0>), ('conv4_block1_1_relu', <tensorflow.python.keras.layers.core.Activation object at 0x000001A6834F34F0>), ('conv4_block1_2_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A6834F3640>), ('conv4_block1_2_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A6834F3B50>), ('conv4_block1_2_relu', <tensorflow.python.keras.layers.core.Activation object at 0x000001A6834F3FD0>), ('conv4_block1_0_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A6834F3C40>), ('conv4_block1_3_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A6837BF6A0>), ('conv4_block1_0_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A6837BFBB0>), ('conv4_block1_3_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A6837BFCA0>), ('conv4_block1_add', <tensorflow.python.keras.layers.merge.Add object at 0x000001A6837CB4F0>), ('conv4_block1_out', <tensorflow.python.keras.layers.core.Activation object at 0x000001A6837CB640>), ('conv4_block2_1_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A6837CB790>), ('conv4_block2_1_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A6837CBD00>), ('conv4_block2_1_relu', <tensorflow.python.keras.layers.core.Activation object at 0x000001A6837CBE50>), ('conv4_block2_2_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A6837CBDF0>), ('conv4_block2_2_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A6837CE850>), ('conv4_block2_2_relu', <tensorflow.python.keras.layers.core.Activation object at 0x000001A6837CED00>), ('conv4_block2_3_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A6837CEE50>), ('conv4_block2_3_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A6837CEFA0>), ('conv4_block2_add', <tensorflow.python.keras.layers.merge.Add object at 0x000001A6837C7DF0>), ('conv4_block2_out', <tensorflow.python.keras.layers.core.Activation object at 0x000001A6837C7640>), ('conv4_block3_1_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A6837C7190>), ('conv4_block3_1_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A6837C73A0>), ('conv4_block3_1_relu', <tensorflow.python.keras.layers.core.Activation object at 0x000001A6837AA550>), ('conv4_block3_2_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A6837AA6A0>), ('conv4_block3_2_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A6837AABB0>), ('conv4_block3_2_relu', <tensorflow.python.keras.layers.core.Activation object at 0x000001A6837AAFD0>), ('conv4_block3_3_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A6837AACA0>), ('conv4_block3_3_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A6837B8700>), ('conv4_block3_add', <tensorflow.python.keras.layers.merge.Add object at 0x000001A6837B8BB0>), ('conv4_block3_out', <tensorflow.python.keras.layers.core.Activation object at 0x000001A6837B8D00>), ('conv4_block4_1_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A6837B8E50>), ('conv4_block4_1_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A6837B8C40>), ('conv4_block4_1_relu', <tensorflow.python.keras.layers.core.Activation object at 0x000001A6834308B0>), ('conv4_block4_2_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A683430A00>), ('conv4_block4_2_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A683430F10>), ('conv4_block4_2_relu', <tensorflow.python.keras.layers.core.Activation object at 0x000001A683464400>), ('conv4_block4_3_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A683430FD0>), ('conv4_block4_3_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A683464A60>), ('conv4_block4_add', <tensorflow.python.keras.layers.merge.Add object at 0x000001A683464F10>), ('conv4_block4_out', <tensorflow.python.keras.layers.core.Activation object at 0x000001A683464F70>), ('conv4_block5_1_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A683464FA0>), ('conv4_block5_1_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A68344C760>), ('conv4_block5_1_relu', <tensorflow.python.keras.layers.core.Activation object at 0x000001A68344CC10>), ('conv4_block5_2_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A68344CD60>), ('conv4_block5_2_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A68344CFD0>), ('conv4_block5_2_relu', <tensorflow.python.keras.layers.core.Activation object at 0x000001A683443760>), ('conv4_block5_3_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A6834438B0>), ('conv4_block5_3_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A683443DC0>), ('conv4_block5_add', <tensorflow.python.keras.layers.merge.Add object at 0x000001A683443F10>), ('conv4_block5_out', <tensorflow.python.keras.layers.core.Activation object at 0x000001A683440400>), ('conv4_block6_1_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A683443EB0>), ('conv4_block6_1_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A683440AC0>), ('conv4_block6_1_relu', <tensorflow.python.keras.layers.core.Activation object at 0x000001A683440F70>), ('conv4_block6_2_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A683440F40>), ('conv4_block6_2_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A68343B610>), ('conv4_block6_2_relu', <tensorflow.python.keras.layers.core.Activation object at 0x000001A68343BAC0>), ('conv4_block6_3_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A68343BC10>), ('conv4_block6_3_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A68343BF10>), ('conv4_block6_add', <tensorflow.python.keras.layers.merge.Add object at 0x000001A6852D3610>), ('conv4_block6_out', <tensorflow.python.keras.layers.core.Activation object at 0x000001A6852D3760>), ('conv5_block1_1_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A6852D38B0>), ('conv5_block1_1_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A6852D3E20>), ('conv5_block1_1_relu', <tensorflow.python.keras.layers.core.Activation object at 0x000001A6852D3F70>), ('conv5_block1_2_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A6852D3F10>), ('conv5_block1_2_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A6852DA970>), ('conv5_block1_2_relu', <tensorflow.python.keras.layers.core.Activation object at 0x000001A6852DAE20>), ('conv5_block1_0_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A6852DAF70>), ('conv5_block1_3_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A6852DADF0>), ('conv5_block1_0_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A6852CE9D0>), ('conv5_block1_3_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A6852CEE50>), ('conv5_block1_add', <tensorflow.python.keras.layers.merge.Add object at 0x000001A6852CEEB0>), ('conv5_block1_out', <tensorflow.python.keras.layers.core.Activation object at 0x000001A6852C4460>), ('conv5_block2_1_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A6852CEF40>), ('conv5_block2_1_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A6852C4B20>), ('input_5', <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x000001A6852C4FA0>), ('conv5_block2_1_relu', <tensorflow.python.keras.layers.core.Activation object at 0x000001A6852DD430>), ('block1_conv1', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A6852DD580>), ('conv5_block2_2_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A6852DDA30>), ('block1_conv2', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A6852DDF40>), ('conv5_block2_2_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A6852DDD30>), ('block1_pool', <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000001A6852E0910>), ('conv5_block2_2_relu', <tensorflow.python.keras.layers.core.Activation object at 0x000001A6852E0BB0>), ('block2_conv1', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A6852E0D00>), ('conv5_block2_3_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A6852E0F70>), ('block2_conv2', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A6852E5760>), ('conv5_block2_3_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A6852E5C70>), ('block2_pool', <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000001A6852E5D60>), ('conv5_block2_add', <tensorflow.python.keras.layers.merge.Add object at 0x000001A6852E93D0>), ('block3_conv1', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A6852E9430>), ('conv5_block2_out', <tensorflow.python.keras.layers.core.Activation object at 0x000001A6852E9A00>), ('block3_conv2', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A6852E9BE0>), ('conv5_block3_1_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A6852E9EE0>), ('block3_conv3', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A6852ED640>), ('conv5_block3_1_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A6852EDB50>), ('block3_pool', <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000001A6852EDC40>), ('conv5_block3_1_relu', <tensorflow.python.keras.layers.core.Activation object at 0x000001A4621302B0>), ('block4_conv1', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A462130400>), ('conv5_block3_2_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A462130910>), ('block4_conv2', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A462130E20>), ('conv5_block3_2_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A462130F70>), ('block4_conv3', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A4621347F0>), ('conv5_block3_2_relu', <tensorflow.python.keras.layers.core.Activation object at 0x000001A462134CA0>), ('block4_pool', <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000001A462134E80>), ('conv5_block3_3_conv', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A462134F40>), ('block5_conv1', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A462137640>), ('conv5_block3_3_bn', <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001A462137B50>), ('block5_conv2', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A462137C40>), ('conv5_block3_add', <tensorflow.python.keras.layers.merge.Add object at 0x000001A46213B4C0>), ('block5_conv3', <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A46213B580>), ('conv5_block3_out', <tensorflow.python.keras.layers.core.Activation object at 0x000001A46213BB80>), ('block5_pool', <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000001A46213BD60>), ('flatten_3', <tensorflow.python.keras.layers.core.Flatten object at 0x000001A46213E070>), ('flatten_4', <tensorflow.python.keras.layers.core.Flatten object at 0x000001A46213E0A0>), ('dropout_2', <tensorflow.python.keras.layers.core.Dropout object at 0x000001A46213BF40>), ('dropout_3', <tensorflow.python.keras.layers.core.Dropout object at 0x000001A46213E3A0>), ('dense_3', <tensorflow.python.keras.layers.core.Dense object at 0x000001A46213E5B0>), ('dense_4', <tensorflow.python.keras.layers.core.Dense object at 0x000001A46213EAF0>), ('tf.math.multiply_2', <tensorflow.python.keras.layers.core.TFOpLambda object at 0x0000019D8002DD00>), ('tf.math.multiply_3', <tensorflow.python.keras.layers.core.TFOpLambda object at 0x000001A46213EE20>), ('concatenate_9', <tensorflow.python.keras.layers.merge.Concatenate object at 0x000001A46213EFA0>), ('dense_5', <tensorflow.python.keras.layers.core.Dense object at 0x000001A46213EEE0>)]\n"
     ]
    }
   ],
   "source": [
    "#%% \n",
    "from keras import backend as K\n",
    "def get_output_layer(model, layer_name):\n",
    "    # get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "    layer_dict = dict([(layer.name, layer) for layer in ensemble_model.layers])\n",
    "    layer = layer_dict[layer_name]\n",
    "    return layer\n",
    "\n",
    "print([(layer.name, layer) for layer in ensemble_model.layers])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先把test folder中的npy檔轉為png，tSNE才能匯入圖片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvt_to_png import cvt_to_png\n",
    "# src_folder=r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\test'\n",
    "# png_folder=r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\test_png'\n",
    "\n",
    "\n",
    "src_folder=r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\test'\n",
    "png_folder=r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\test_png'\n",
    "\n",
    "\n",
    "cvt_to_png(src_folder,png_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更改import進來的函式，記得用importlib.reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tSNE' from 'D:\\\\OCT\\\\dental OCT\\\\bare tooth\\\\ensemble_model_aug\\\\code\\\\reqiured_funcs\\\\tSNE.py'>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import sys\n",
    "\n",
    "\n",
    "# 添加函式檔案的路徑\n",
    "sys.path.append(r\"D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\reqiured_funcs\")\n",
    "\n",
    "# 假設你的函式在 my_functions.py 中\n",
    "import tSNE\n",
    "\n",
    "# 確保加載最新版本\n",
    "importlib.reload(tSNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何匯入指定日期的pkl? 直接手動copy最方便"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels shape: (9370, 1)\n",
      "Test labels shape: (3850, 1)\n"
     ]
    }
   ],
   "source": [
    "import os,load_save_pkl\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     save_dir = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\pkl' # 替换为实际的保存路径\n",
    "#     # 如果日期文件夹不存在，则创建它\n",
    "#     if not os.path.exists(save_dir):\n",
    "#         os.makedirs(save_dir)\n",
    "    \n",
    "#     train_nor_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\train\\nor'\n",
    "#     test_nor_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\test\\nor'\n",
    "#     train_cal_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\train\\cal'\n",
    "#     test_cal_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\test\\cal'\n",
    "\n",
    "\n",
    "#OCTA\n",
    "if __name__ == \"__main__\":\n",
    "    save_dir = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\pkl' # 替换为实际的保存路径\n",
    "    # 如果日期文件夹不存在，则创建它\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    train_nor_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\train\\nor'\n",
    "    test_nor_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\test\\nor'\n",
    "    train_cal_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\train\\cal'\n",
    "    test_cal_path = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\test\\cal'\n",
    "\n",
    "\n",
    "\n",
    "    load_save_pkl.generate_and_save_data(train_nor_path, train_cal_path, test_nor_path, test_cal_path, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os,load_save_pkl \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    save_dir = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\pkl'  # 替换为实际的保存路径\n",
    "    file_name=\"data.pkl\"\n",
    "    date=\"2024-05-26\"\n",
    "\n",
    "    try:\n",
    "        train_data, train_labels,test_data,test_labels = load_save_pkl.load_data_pickle(save_dir, file_name,date)\n",
    "        print(\"Data loaded successfully.\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "\n",
    "#OCTA\n",
    "if __name__ == \"__main__\":\n",
    "    save_dir = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dc_OCTA\\pkl'  # 替换为实际的保存路径\n",
    "    file_name=\"data.pkl\"\n",
    "    date=\"2024-05-26\"\n",
    "\n",
    "    try:\n",
    "        train_data, train_labels,test_data,test_labels = load_save_pkl.load_data_pickle(save_dir, file_name,date)\n",
    "        print(\"Data loaded successfully.\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "\n",
    "#tSNE只需要使用到test_data, test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# 指定模型檔案路徑:記得從日期那邊微調路徑!\n",
    "model_path = r\"D:/OCT/dental OCT/bare tooth/ensemble_model_aug/best_results/2024-05-25/ensemble_ResNet50_0.5_&VGG16_0.5_SGD_acc=0.7403.h5\"\n",
    "# 載入模型\n",
    "ensemble_model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "很多藍點Cal，Predicted label卻顯示nor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最佳結果(不亂動)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有可能遇到緩存問題導致一直出現之前的錯誤結果!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tSNE import plot_and_save_tSNE #會有緩存問題，必須reload修訂版函式\n",
    "\n",
    "import tSNE \n",
    "\n",
    "# Load images from folder\n",
    "cal_folder = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\test_png\\cal'\n",
    "nor_folder = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\code\\2024_dentalCalculus\\test_png\\nor'\n",
    "\n",
    "#save tSNE img\n",
    "save_dir = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\tSNE'\n",
    "\n",
    "#2nd 參數請比照get_output_layer的最後一個layer.name\n",
    "#tSNE.plot_and_save_tSNE(ensemble_model,'dense_5',[test_data,test_data],test_labels,save_dir,cal_folder,nor_folder, label_name=['Nor', 'Cal'])\n",
    "tSNE.plot_tSNE_latest(ensemble_model, 'dense_5', [test_data,test_data], test_labels, save_dir, cal_folder, nor_folder, label_name=['Nor', 'Cal'])\n",
    "#tSNE.plot_tSNE_try(ensemble_model,'dense_5',[test_data,test_data],test_labels,save_dir,cal_folder,nor_folder,label_name= ['Nor', 'Cal'])\n",
    "\n",
    "#添加資訊，此Nor/Cal 樣本來自於nor1~nor7/supra1~supra5的哪筆data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要使用 k 最近鄰（KNN）來繪製 t-SNE 圖中的 cal 和 nor 的邊界，你可以執行以下步驟：\n",
    "\n",
    "使用 t-SNE 轉換後的二維特徵表示（Y）作為訓練數據的特徵。\n",
    "將資料點的真實標籤（cal 或 nor）作為訓練數據的目標標籤。\n",
    "初始化並訓練 k 最近鄰分類器。\n",
    "繪製分界線。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 使用 t-SNE 轉換後的二維特徵表示作為訓練數據的特徵\n",
    "X_train = Y\n",
    "\n",
    "# 將資料點的真實標籤（cal 或 nor）作為訓練數據的目標標籤\n",
    "y_train = df['label'].values\n",
    "\n",
    "# # 初始化並訓練 k 最近鄰分類器\n",
    "# knn = KNeighborsClassifier(n_neighbors=5)\n",
    "# knn.fit(X_train, y_train)\n",
    "\n",
    "batch_size = 1000  # 定義批次大小\n",
    "\n",
    "# 初始化並訓練 k 最近鄰分類器\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# 將資料分成多個批次處理\n",
    "for i in range(0, len(X_train), batch_size):\n",
    "    X_batch = X_train[i:i+batch_size]\n",
    "    y_batch = y_train[i:i+batch_size]\n",
    "    # knn.partial_fit(X_batch, y_batch, classes=np.unique(y_train))\n",
    "    knn.fit(X_batch, y_batch, classes=np.unique(y_train))\n",
    "# 定義繪製分界線的函數\n",
    "def plot_decision_boundary(model, ax, X, y):\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                         np.arange(y_min, y_max, 0.01))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])   # ravel會出事!! -> MemoryError: Unable to allocate 16.1 GiB for an array with shape (432326650, 5) and data type int64\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax.contour(xx, yy, Z, alpha=0.5)\n",
    "\n",
    "# 生成 t-SNE 圖\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.margins(0.05)\n",
    "\n",
    "# 繪製 t-SNE 散點圖\n",
    "for label, group in groups:\n",
    "    ax.plot(group.x, group.y, marker='o', linestyle='', ms=5, label=label, alpha=0.8)\n",
    "\n",
    "# 繪製分界線\n",
    "plot_decision_boundary(knn, ax, X_train, y_train)\n",
    "\n",
    "# 添加圖例\n",
    "ax.legend()\n",
    "\n",
    "plt.title('tSNE with Decision Boundary (KNN)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "為了解決MemError這個問題，你可以採取以下幾種方法：\n",
    "\n",
    "減少資料量：可以減少資料集的大小，例如僅使用部分資料點進行模型訓練和預測，這樣可以減少記憶體的使用量。\n",
    "增加記憶體：如果你的硬體設備允許，可以增加系統的記憶體，這樣就可以容納更大的資料集。\n",
    "使用近似方法：可以考慮使用近似的最近鄰算法，例如 Ball Tree 或 KD Tree，這些方法可以減少記憶體的使用量。\n",
    "使用分批處理：可以將資料分成多個批次進行處理，這樣可以降低每個批次的記憶體使用量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用code畫出TSNE中，nor跟cal邊界"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結合gradCAM資訊到TSNE 高難度!!(可做可不做，自行選擇)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "整合版(下方附分解後的子函式，以便觀察OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from PIL import Image as PILImage\n",
    "from IPython.display import display, Image as IPImage\n",
    "from keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "import keras.applications.xception as xception\n",
    "\n",
    "# Function to extract image name without extension\n",
    "def extract_image_name(filename):\n",
    "    return os.path.splitext(filename)[0]\n",
    "\n",
    "def generate_and_display_gradcam(img_path, model_builder, last_conv_layer_name, preprocess_input, decode_predictions, img_size=(299, 299), alpha=0.4, cam_path=\"save_cam_image.jpg\", original_name=None):\n",
    "    # Load image\n",
    "    def get_img_array(img_path, size):\n",
    "        img = load_img(img_path, target_size=size)\n",
    "        array = img_to_array(img)\n",
    "        array = np.expand_dims(array, axis=0)\n",
    "        return array\n",
    "\n",
    "    # Generate Grad-CAM heatmap\n",
    "    def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "        grad_model = tf.keras.models.Model(\n",
    "            [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "        )\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            last_conv_layer_output, preds = grad_model(img_array)\n",
    "            if pred_index is None:\n",
    "                pred_index = tf.argmax(preds[0])\n",
    "            class_channel = preds[:, pred_index]\n",
    "\n",
    "        grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "        last_conv_layer_output = last_conv_layer_output[0]\n",
    "\n",
    "        cam = tf.reduce_sum(tf.multiply(pooled_grads, last_conv_layer_output), axis=-1)\n",
    "        cam = tf.nn.relu(cam)\n",
    "\n",
    "        heatmap = cam / tf.reduce_max(cam)\n",
    "        return heatmap.numpy()\n",
    "\n",
    "    # Save and display Grad-CAM\n",
    "    def save_and_display_gradcam(img_path, heatmap, cam_path=\"save_cam_image.jpg\", alpha=0.4):\n",
    "        img = load_img(img_path)\n",
    "        img = img_to_array(img)\n",
    "\n",
    "        heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "        jet = mpl.cm.get_cmap(\"jet\")\n",
    "\n",
    "        jet_colors = jet(np.arange(256))[:, :3]\n",
    "        jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "        jet_heatmap = array_to_img(jet_heatmap)\n",
    "        jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "        jet_heatmap = img_to_array(jet_heatmap)\n",
    "\n",
    "        Superimposed_img = jet_heatmap * alpha + img\n",
    "        Superimposed_img = array_to_img(Superimposed_img)\n",
    "\n",
    "        Superimposed_img.save(cam_path)\n",
    "        display(IPImage(cam_path))\n",
    "\n",
    "  \n",
    "\n",
    "    # Preprocess and prepare the image\n",
    "    img_array = preprocess_input(get_img_array(img_path, size=img_size))\n",
    "\n",
    "    # Make model with imagenet dataset\n",
    "    model = model_builder(weights=\"imagenet\")\n",
    "    model.layers[-1].activation = None\n",
    "\n",
    "    # Generate Grad-CAM heatmap\n",
    "    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
    "\n",
    "    # Save and display Grad-CAM\n",
    "    save_and_display_gradcam(img_path, heatmap, cam_path=cam_path, alpha=alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BOIL\\AppData\\Local\\Temp\\ipykernel_8908\\3861457684.py:53: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  jet = mpl.cm.get_cmap(\"jet\")\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_png_path = r'\\\\BOIL-NAS\\home\\Dental OCT\\tooth_data_png\\201903220033.png'\n",
    "\n",
    "# Call the function with required parameters\n",
    "generate_and_display_gradcam(\n",
    "    img_path=output_png_path,\n",
    "    model_builder=xception.Xception,\n",
    "    last_conv_layer_name=\"block14_sepconv2_act\",\n",
    "    preprocess_input=xception.preprocess_input,\n",
    "    decode_predictions=xception.decode_predictions,\n",
    "    img_size=(299, 299),\n",
    "    alpha=0.4,\n",
    "    cam_path=\"save_cam_image.jpg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何讓cal/nor_folder跟cal/nor_folder_CAM的影像對的上?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #有bug 就restart kernel\n",
    "# import os\n",
    "\n",
    "# def delete_files_in_directory(directory):\n",
    "#     # 遍历目录中的所有文件和子目录\n",
    "#     for root, dirs, files in os.walk(directory):\n",
    "#         # 删除所有文件\n",
    "#         for file in files:\n",
    "#             file_path = os.path.join(root, file)\n",
    "#             os.remove(file_path)\n",
    "#             print(f\"Deleted {file_path}\")\n",
    "        \n",
    "#         # 递归删除子目录中的所有文件\n",
    "#         for dir in dirs:\n",
    "#             subdir_path = os.path.join(root, dir)\n",
    "#             delete_files_in_directory(subdir_path)\n",
    "\n",
    "# # 要删除文件的目录路径\n",
    "# directory_to_clean = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\test_png_CAM\\cal_CAM'\n",
    "\n",
    "# # 删除目录中的所有文件\n",
    "# delete_files_in_directory(directory_to_clean)\n",
    "\n",
    "# print(\"All files have been deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "依序編號file並自己改名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# # 指定原始图片文件夹和目标文件夹\n",
    "# source_folder = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\test_png\\cal'\n",
    "# target_folder = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\test_png\\cal_renamed'\n",
    "\n",
    "# # 确保目标文件夹存在，如果不存在则创建\n",
    "# if not os.path.exists(target_folder):\n",
    "#     os.makedirs(target_folder)\n",
    "\n",
    "# # 获取原始文件夹中的所有图片文件\n",
    "# image_files = [file for file in os.listdir(source_folder) if file.endswith('.png')]\n",
    "\n",
    "# # 遍历图片文件，并按照指定规则重命名\n",
    "# for i, filename in enumerate(image_files):\n",
    "#     new_filename = f'cal_test_{i+1}.png'\n",
    "#     source_path = os.path.join(source_folder, filename)\n",
    "#     target_path = os.path.join(target_folder, new_filename)\n",
    "#     shutil.copyfile(source_path, target_path)\n",
    "\n",
    "# print(\"图片重命名完成！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图片重命名完成！\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# 指定原始图片文件夹和目标文件夹\n",
    "source_folder = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\test_png\\nor'\n",
    "target_folder = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\test_png\\nor_renamed'\n",
    "\n",
    "# 确保目标文件夹存在，如果不存在则创建\n",
    "if not os.path.exists(target_folder):\n",
    "    os.makedirs(target_folder)\n",
    "\n",
    "# 获取原始文件夹中的所有图片文件\n",
    "image_files = [file for file in os.listdir(source_folder) if file.endswith('.png')]\n",
    "\n",
    "# 遍历图片文件，并按照指定规则重命名\n",
    "for i, filename in enumerate(image_files):\n",
    "    new_filename = f'nor_test_{i+1}.png'\n",
    "    source_path = os.path.join(source_folder, filename)\n",
    "    target_path = os.path.join(target_folder, new_filename)\n",
    "    shutil.copyfile(source_path, target_path)\n",
    "\n",
    "print(\"图片重命名完成！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CAM folders\n",
    "cal_folder = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\test_png\\cal_renamed'\n",
    "nor_folder = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\test_png\\nor_renamed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_and_display_gradcam(\n",
    "#     img_path=output_png_path,\n",
    "#     model_builder=xception.Xception,\n",
    "#     last_conv_layer_name=\"block14_sepconv2_act\",\n",
    "#     preprocess_input=xception.preprocess_input,\n",
    "#     decode_predictions=xception.decode_predictions,\n",
    "#     img_size=(299, 299),\n",
    "#     alpha=0.4,\n",
    "#     cam_path=\"save_cam_image.jpg\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the original image folders\n",
    "cal_folder = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\test_png\\cal_renamed'\n",
    "nor_folder = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\test_png\\nor_renamed'\n",
    "\n",
    "# Define the CAM folders\n",
    "cal_folder_CAM = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\test_png_CAM\\cal_CAM'\n",
    "nor_folder_CAM = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\test_png_CAM\\nor_CAM'\n",
    "\n",
    "# Check if the CAM folders exist, if not, create them\n",
    "if not os.path.exists(cal_folder_CAM):\n",
    "    os.makedirs(cal_folder_CAM)\n",
    "\n",
    "if not os.path.exists(nor_folder_CAM):\n",
    "    os.makedirs(nor_folder_CAM)\n",
    "\n",
    "# Function to extract image name without extension\n",
    "def extract_image_name(filename):\n",
    "    return os.path.splitext(filename)[0]\n",
    "\n",
    "# Process images in cal_folder\n",
    "cal_files = os.listdir(cal_folder)\n",
    "cal_files.sort()  # Sort the files\n",
    "for i, filename in enumerate(cal_files):\n",
    "    img_path = os.path.join(cal_folder, filename)\n",
    "    cam_path = os.path.join(cal_folder_CAM, f\"cal_CAM_{i+1}.jpg\")  # Modify the cam_path for saving Grad-CAM result\n",
    "    original_name = extract_image_name(filename)  \n",
    "    generate_and_display_gradcam(img_path=img_path, model_builder=xception.Xception,\n",
    "                                 last_conv_layer_name=\"block14_sepconv2_act\",\n",
    "                                 preprocess_input=xception.preprocess_input,\n",
    "                                 decode_predictions=xception.decode_predictions,\n",
    "                                 cam_path=cam_path,\n",
    "                                 original_name=original_name)  #多一個original_name，要添加到舊函式\n",
    "\n",
    "# Process images in nor_folder\n",
    "nor_files = os.listdir(nor_folder)\n",
    "nor_files.sort()  # Sort the files\n",
    "for i, filename in enumerate(nor_files):\n",
    "    img_path = os.path.join(nor_folder, filename)\n",
    "    cam_path = os.path.join(nor_folder_CAM, f\"nor_CAM_{i+1}.jpg\")  # Modify the cam_path for saving Grad-CAM result\n",
    "    original_name = extract_image_name(filename)  \n",
    "    generate_and_display_gradcam(img_path=img_path,  model_builder=xception.Xception,\n",
    "                                 last_conv_layer_name=\"block14_sepconv2_act\",\n",
    "                                 preprocess_input=xception.preprocess_input,\n",
    "                                 decode_predictions=xception.decode_predictions,\n",
    "                                 cam_path=cam_path,\n",
    "                                 original_name=original_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the CAM folders\n",
    "cal_folder_CAM = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\test_png_CAM\\cal_CAM'\n",
    "nor_folder_CAM = r'D:\\OCT\\dental OCT\\bare tooth\\ensemble_model_aug\\test_png_CAM\\nor_CAM'\n",
    "\n",
    "# Check if the CAM folders exist, if not, create them\n",
    "if not os.path.exists(cal_folder_CAM):\n",
    "    os.makedirs(cal_folder_CAM)\n",
    "\n",
    "if not os.path.exists(nor_folder_CAM):\n",
    "    os.makedirs(nor_folder_CAM)\n",
    "\n",
    "# Process images in cal_folder\n",
    "for filename in os.listdir(cal_folder):\n",
    "    img_path = os.path.join(cal_folder, filename)\n",
    "    cam_path = os.path.join(cal_folder_CAM, f\"{filename.split('.')[0]}_CAM.jpg\")  # Modify the cam_path for saving Grad-CAM result\n",
    "    generate_and_display_gradcam(\n",
    "        img_path=img_path,\n",
    "        model_builder=xception.Xception,\n",
    "        last_conv_layer_name=\"block14_sepconv2_act\",\n",
    "        preprocess_input=xception.preprocess_input,\n",
    "        decode_predictions=xception.decode_predictions,\n",
    "        img_size=(299, 299),\n",
    "        alpha=0.4,\n",
    "        cam_path=cam_path\n",
    "    )\n",
    "\n",
    "# Process images in nor_folder\n",
    "for filename in os.listdir(nor_folder):\n",
    "    img_path = os.path.join(nor_folder, filename)\n",
    "    cam_path = os.path.join(nor_folder_CAM, f\"{filename.split('.')[0]}_CAM.jpg\")  # Modify the cam_path for saving Grad-CAM result\n",
    "    generate_and_display_gradcam(\n",
    "        img_path=img_path,\n",
    "        model_builder=xception.Xception,\n",
    "        last_conv_layer_name=\"block14_sepconv2_act\",\n",
    "        preprocess_input=xception.preprocess_input,\n",
    "        decode_predictions=xception.decode_predictions,\n",
    "        img_size=(299, 299),\n",
    "        alpha=0.4,\n",
    "        cam_path=cam_path\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from IPython.display import Image as IPImage, display\n",
    "\n",
    "model_builder = keras.applications.xception.Xception\n",
    "img_size = (299, 299)\n",
    "preprocess_input = keras.applications.xception.preprocess_input\n",
    "decode_predictions = keras.applications.xception.decode_predictions\n",
    "\n",
    "last_conv_layer_name = \"block14_sepconv2_act\"\n",
    "\n",
    "output_png_path = r'\\\\BOIL-NAS\\home\\Dental OCT\\tooth_data_png\\201903220033.png'\n",
    "\n",
    "\n",
    "\n",
    "## The local path to our target image\n",
    "\n",
    "#img_path= output_png_path\n",
    "#img_path=r'C:\\Users\\BOIL\\OneDrive\\圖片\\nancy_graph\\初戀.png'\n",
    "\n",
    "# 打开 TIFF 文件\n",
    "\n",
    "#display(IPImage(img_path))  # 秀原圖\n",
    "display(IPImage(output_png_path))\n",
    "\n",
    "\n",
    "\"\"\"利用load_img載入圖像並用img_to_array轉成array，並擴展維度，跟pretrained好的Xception model互相匹配\"\"\"\n",
    "def get_img_array(img_path, size):\n",
    "    ## `img` is a PIL image \n",
    "    img = load_img(img_path, target_size=size)\n",
    "    array = img_to_array(img)\n",
    "    ## We add a dimension to transform our array into a \"batch\" : because model expect input_shape:(batch_size, height, width, channels)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "\"\"\"從輸入映射到輸出\"\"\"\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    ## First, we create a model that maps the input image to the activations\n",
    "    ## of the last conv layer as well as the output predictions\n",
    "    grad_model = keras.models.Model(\n",
    "        model.inputs, [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    ## Then, we compute the gradient of the top predicted class for our input image\n",
    "    ## for the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    ## We are doing transfer learning on last layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    ## This is a vector where each entry is the mean intensity of the gradient : use global average pooling\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "\n",
    "    ## calculates a heatmap highlighting the regions of importance in an image\n",
    "    ## for a specific \n",
    "    ## predicted class by combining the output of the last convolutional layer\n",
    "    ## with the pooled gradients.\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "\n",
    "    #原本算法\n",
    "    # heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]  # GAP\n",
    "    # heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # ## For visualization purpose\n",
    "    # heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "\n",
    "    #試看看別種計算grad方式，看是否能降噪\n",
    "    # 计算CAM\n",
    "    cam = tf.reduce_sum(tf.multiply(pooled_grads, last_conv_layer_output), axis=-1)\n",
    "    cam = tf.nn.relu(cam)\n",
    "\n",
    "    # 归一化CAM\n",
    "    heatmap = cam / tf.reduce_max(cam)\n",
    "\n",
    "    return heatmap.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted of image: [('n03388043', 'fountain', 5.3040624)]\n"
     ]
    }
   ],
   "source": [
    "## Preparing the image\n",
    "img_array = preprocess_input(get_img_array(output_png_path, size=img_size))\n",
    "\n",
    "## Making the model with imagenet dataset\n",
    "model = model_builder(weights=\"imagenet\")\n",
    "\n",
    "## Remove last layer's softmax(transfer learning)\n",
    "model.layers[-1].activation = None\n",
    "\n",
    "preds = model.predict(img_array)\n",
    "print(\"Predicted of image:\", decode_predictions(preds, top=1)[0])\n",
    "\n",
    "## Generate class activation heatmap\n",
    "heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_display_gradcam(img_path, heatmap, cam_path=\"save_cam_image.jpg\", alpha=0.4):\n",
    "    ## Loading the original image\n",
    "    img = load_img(img_path)\n",
    "    img = img_to_array(img)\n",
    "\n",
    "    ## Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    ## Use jet colormap to colorize heatmap\n",
    "    jet = mpl.colormaps[\"jet\"]\n",
    "\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    ## Create an image with RGB colorized heatmap\n",
    "    jet_heatmap = array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = img_to_array(jet_heatmap)\n",
    "\n",
    "    ## Superimpose the heatmap on original image\n",
    "    Superimposed_img = jet_heatmap * alpha + img\n",
    "    Superimposed_img = array_to_img(Superimposed_img)\n",
    "\n",
    "    ## Save the superimposed image\n",
    "    Superimposed_img.save(cam_path)\n",
    "   \n",
    "\n",
    "    ## Displaying Grad CAM\n",
    "    display(IPImage(cam_path))\n",
    "\n",
    "\n",
    "save_and_display_gradcam(output_png_path, heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "output_png_path = r'\\\\BOIL-NAS\\homes\\311514061\\Dental OCT\\tooth_data_png'\n",
    "save_cam_path=r'\\\\BOIL-NAS\\homes\\311514061\\Dental OCT\\tooth_data_cam'\n",
    "os.makedirs(save_cam_path,exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "# Get a sorted list of filenames\n",
    "sorted_filenames = sorted([filename for filename in os.listdir(output_png_path) if filename.endswith('.png')])  # 照順序輸出png檔\n",
    "for filename in sorted_filenames:\n",
    "    #print(filename)\n",
    "    img_array = preprocess_input(get_img_array(output_png_path, size=img_size))\n",
    "\n",
    "\n",
    "    preds = model.predict(img_array)\n",
    "    \n",
    "    ## Generate class activation heatmap\n",
    "    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
    "    save_and_display_gradcam(output_png_path, heatmap, cam_path=os.path.join(save_cam_path, filename))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
